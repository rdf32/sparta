Loading analytics/1.04.0000.202011101237_0264
  Loading requirement: crayai/0.6.0000.202008211107_0069
Segmentation Models: using `tf.keras` framework.
Loading data
Training -> Samples: 127905,  Targets: 127905
Validation -> Samples: 127905,  Targets: 127905
Steps per Training Epoch -> 124
Steps per Validation Epoch -> 124
['GPU:0', 'GPU:1', 'GPU:2', 'GPU:3']
Compiling and returning model
Model: "TransformerEncoderMLP"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 19, 6)]      0           []                               
                                                                                                  
 positional_embedding (Position  (None, 19, 6)       0           ['input_1[0][0]']                
 alEmbedding)                                                                                     
                                                                                                  
 dropout (Dropout)              (None, 19, 6)        0           ['positional_embedding[0][0]']   
                                                                                                  
 layer_normalization (LayerNorm  (None, 19, 6)       12          ['dropout[0][0]']                
 alization)                                                                                       
                                                                                                  
 multi_head_attention (MultiHea  (None, 19, 6)       978         ['layer_normalization[0][0]',    
 dAttention)                                                      'layer_normalization[0][0]',    
                                                                  'layer_normalization[0][0]']    
                                                                                                  
 add (Add)                      (None, 19, 6)        0           ['dropout[0][0]',                
                                                                  'multi_head_attention[0][0]']   
                                                                                                  
 layer_normalization_1 (LayerNo  (None, 19, 6)       12          ['add[0][0]']                    
 rmalization)                                                                                     
                                                                                                  
 dense (Dense)                  (None, 19, 24)       168         ['layer_normalization_1[0][0]']  
                                                                                                  
 dense_1 (Dense)                (None, 19, 6)        150         ['dense[0][0]']                  
                                                                                                  
 dropout_1 (Dropout)            (None, 19, 6)        0           ['dense_1[0][0]']                
                                                                                                  
 add_1 (Add)                    (None, 19, 6)        0           ['add[0][0]',                    
                                                                  'dropout_1[0][0]']              
                                                                                                  
 layer_normalization_2 (LayerNo  (None, 19, 6)       12          ['add_1[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_1 (MultiH  (None, 19, 6)       978         ['layer_normalization_2[0][0]',  
 eadAttention)                                                    'layer_normalization_2[0][0]',  
                                                                  'layer_normalization_2[0][0]']  
                                                                                                  
 add_2 (Add)                    (None, 19, 6)        0           ['add_1[0][0]',                  
                                                                  'multi_head_attention_1[0][0]'] 
                                                                                                  
 layer_normalization_3 (LayerNo  (None, 19, 6)       12          ['add_2[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_2 (Dense)                (None, 19, 24)       168         ['layer_normalization_3[0][0]']  
                                                                                                  
 dense_3 (Dense)                (None, 19, 6)        150         ['dense_2[0][0]']                
                                                                                                  
 dropout_2 (Dropout)            (None, 19, 6)        0           ['dense_3[0][0]']                
                                                                                                  
 add_3 (Add)                    (None, 19, 6)        0           ['add_2[0][0]',                  
                                                                  'dropout_2[0][0]']              
                                                                                                  
 layer_normalization_4 (LayerNo  (None, 19, 6)       12          ['add_3[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_2 (MultiH  (None, 19, 6)       978         ['layer_normalization_4[0][0]',  
 eadAttention)                                                    'layer_normalization_4[0][0]',  
                                                                  'layer_normalization_4[0][0]']  
                                                                                                  
 add_4 (Add)                    (None, 19, 6)        0           ['add_3[0][0]',                  
                                                                  'multi_head_attention_2[0][0]'] 
                                                                                                  
 layer_normalization_5 (LayerNo  (None, 19, 6)       12          ['add_4[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_4 (Dense)                (None, 19, 24)       168         ['layer_normalization_5[0][0]']  
                                                                                                  
 dense_5 (Dense)                (None, 19, 6)        150         ['dense_4[0][0]']                
                                                                                                  
 dropout_3 (Dropout)            (None, 19, 6)        0           ['dense_5[0][0]']                
                                                                                                  
 add_5 (Add)                    (None, 19, 6)        0           ['add_4[0][0]',                  
                                                                  'dropout_3[0][0]']              
                                                                                                  
 layer_normalization_6 (LayerNo  (None, 19, 6)       12          ['add_5[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_3 (MultiH  (None, 19, 6)       978         ['layer_normalization_6[0][0]',  
 eadAttention)                                                    'layer_normalization_6[0][0]',  
                                                                  'layer_normalization_6[0][0]']  
                                                                                                  
 add_6 (Add)                    (None, 19, 6)        0           ['add_5[0][0]',                  
                                                                  'multi_head_attention_3[0][0]'] 
                                                                                                  
 layer_normalization_7 (LayerNo  (None, 19, 6)       12          ['add_6[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_6 (Dense)                (None, 19, 24)       168         ['layer_normalization_7[0][0]']  
                                                                                                  
 dense_7 (Dense)                (None, 19, 6)        150         ['dense_6[0][0]']                
                                                                                                  
 dropout_4 (Dropout)            (None, 19, 6)        0           ['dense_7[0][0]']                
                                                                                                  
 add_7 (Add)                    (None, 19, 6)        0           ['add_6[0][0]',                  
                                                                  'dropout_4[0][0]']              
                                                                                                  
 layer_normalization_8 (LayerNo  (None, 19, 6)       12          ['add_7[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_4 (MultiH  (None, 19, 6)       978         ['layer_normalization_8[0][0]',  
 eadAttention)                                                    'layer_normalization_8[0][0]',  
                                                                  'layer_normalization_8[0][0]']  
                                                                                                  
 add_8 (Add)                    (None, 19, 6)        0           ['add_7[0][0]',                  
                                                                  'multi_head_attention_4[0][0]'] 
                                                                                                  
 layer_normalization_9 (LayerNo  (None, 19, 6)       12          ['add_8[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_8 (Dense)                (None, 19, 24)       168         ['layer_normalization_9[0][0]']  
                                                                                                  
 dense_9 (Dense)                (None, 19, 6)        150         ['dense_8[0][0]']                
                                                                                                  
 dropout_5 (Dropout)            (None, 19, 6)        0           ['dense_9[0][0]']                
                                                                                                  
 add_9 (Add)                    (None, 19, 6)        0           ['add_8[0][0]',                  
                                                                  'dropout_5[0][0]']              
                                                                                                  
 layer_normalization_10 (LayerN  (None, 19, 6)       12          ['add_9[0][0]']                  
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_5 (MultiH  (None, 19, 6)       978         ['layer_normalization_10[0][0]', 
 eadAttention)                                                    'layer_normalization_10[0][0]', 
                                                                  'layer_normalization_10[0][0]'] 
                                                                                                  
 add_10 (Add)                   (None, 19, 6)        0           ['add_9[0][0]',                  
                                                                  'multi_head_attention_5[0][0]'] 
                                                                                                  
 layer_normalization_11 (LayerN  (None, 19, 6)       12          ['add_10[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 dense_10 (Dense)               (None, 19, 24)       168         ['layer_normalization_11[0][0]'] 
                                                                                                  
 dense_11 (Dense)               (None, 19, 6)        150         ['dense_10[0][0]']               
                                                                                                  
 dropout_6 (Dropout)            (None, 19, 6)        0           ['dense_11[0][0]']               
                                                                                                  
 add_11 (Add)                   (None, 19, 6)        0           ['add_10[0][0]',                 
                                                                  'dropout_6[0][0]']              
                                                                                                  
 dense_12 (Dense)               (None, 19, 128)      896         ['add_11[0][0]']                 
                                                                                                  
 dense_13 (Dense)               (None, 19, 256)      33024       ['dense_12[0][0]']               
                                                                                                  
 dense_14 (Dense)               (None, 19, 512)      131584      ['dense_13[0][0]']               
                                                                                                  
 dense_15 (Dense)               (None, 19, 18)       9234        ['dense_14[0][0]']               
                                                                                                  
==================================================================================================
Total params: 182,658
Trainable params: 182,658
Non-trainable params: 0
__________________________________________________________________________________________________
Training model: transformer_encoder_mlp
Using tf.Dataset
Epoch 1/200
  1/124 [..............................] - ETA: 2:25:00 - loss: 2.6087 - masked_accuracy: 0.0057  2/124 [..............................] - ETA: 21s - loss: 2.5912 - masked_accuracy: 0.0090      3/124 [..............................] - ETA: 17s - loss: 2.5697 - masked_accuracy: 0.0152  4/124 [..............................] - ETA: 16s - loss: 2.5562 - masked_accuracy: 0.0281  5/124 [>.............................] - ETA: 16s - loss: 2.5384 - masked_accuracy: 0.0554  6/124 [>.............................] - ETA: 15s - loss: 2.5194 - masked_accuracy: 0.0816  7/124 [>.............................] - ETA: 15s - loss: 2.4990 - masked_accuracy: 0.1052  8/124 [>.............................] - ETA: 14s - loss: 2.4808 - masked_accuracy: 0.1249  9/124 [=>............................] - ETA: 14s - loss: 2.4630 - masked_accuracy: 0.1419 10/124 [=>............................] - ETA: 14s - loss: 2.4459 - masked_accuracy: 0.1555 11/124 [=>............................] - ETA: 14s - loss: 2.4305 - masked_accuracy: 0.1664 12/124 [=>............................] - ETA: 13s - loss: 2.4129 - masked_accuracy: 0.1761 13/124 [==>...........................] - ETA: 13s - loss: 2.3971 - masked_accuracy: 0.1832 14/124 [==>...........................] - ETA: 13s - loss: 2.3801 - masked_accuracy: 0.1909 15/124 [==>...........................] - ETA: 13s - loss: 2.3638 - masked_accuracy: 0.1971 16/124 [==>...........................] - ETA: 13s - loss: 2.3480 - masked_accuracy: 0.2031 17/124 [===>..........................] - ETA: 13s - loss: 2.3330 - masked_accuracy: 0.2073 18/124 [===>..........................] - ETA: 12s - loss: 2.3157 - masked_accuracy: 0.2126 19/124 [===>..........................] - ETA: 12s - loss: 2.3022 - masked_accuracy: 0.2151 20/124 [===>..........................] - ETA: 12s - loss: 2.2882 - masked_accuracy: 0.2182 21/124 [====>.........................] - ETA: 12s - loss: 2.2755 - masked_accuracy: 0.2217 22/124 [====>.........................] - ETA: 12s - loss: 2.2619 - masked_accuracy: 0.2245 23/124 [====>.........................] - ETA: 12s - loss: 2.2498 - masked_accuracy: 0.2268 24/124 [====>.........................] - ETA: 12s - loss: 2.2370 - masked_accuracy: 0.2288 25/124 [=====>........................] - ETA: 12s - loss: 2.2251 - masked_accuracy: 0.2313 26/124 [=====>........................] - ETA: 11s - loss: 2.2147 - masked_accuracy: 0.2325 27/124 [=====>........................] - ETA: 11s - loss: 2.2030 - masked_accuracy: 0.2345 28/124 [=====>........................] - ETA: 11s - loss: 2.1934 - masked_accuracy: 0.2360 29/124 [======>.......................] - ETA: 11s - loss: 2.1833 - masked_accuracy: 0.2381 30/124 [======>.......................] - ETA: 11s - loss: 2.1748 - masked_accuracy: 0.2396 31/124 [======>.......................] - ETA: 11s - loss: 2.1636 - masked_accuracy: 0.2420 32/124 [======>.......................] - ETA: 11s - loss: 2.1550 - masked_accuracy: 0.2433 33/124 [======>.......................] - ETA: 10s - loss: 2.1463 - masked_accuracy: 0.2451 34/124 [=======>......................] - ETA: 10s - loss: 2.1367 - masked_accuracy: 0.2464 35/124 [=======>......................] - ETA: 10s - loss: 2.1286 - masked_accuracy: 0.2477 36/124 [=======>......................] - ETA: 10s - loss: 2.1208 - masked_accuracy: 0.2486 37/124 [=======>......................] - ETA: 10s - loss: 2.1126 - masked_accuracy: 0.2497 38/124 [========>.....................] - ETA: 10s - loss: 2.1081 - masked_accuracy: 0.2500 39/124 [========>.....................] - ETA: 10s - loss: 2.1010 - masked_accuracy: 0.2511 40/124 [========>.....................] - ETA: 10s - loss: 2.0944 - masked_accuracy: 0.2518 41/124 [========>.....................] - ETA: 10s - loss: 2.0886 - masked_accuracy: 0.2524 42/124 [=========>....................] - ETA: 9s - loss: 2.0825 - masked_accuracy: 0.2532  43/124 [=========>....................] - ETA: 9s - loss: 2.0773 - masked_accuracy: 0.2537 44/124 [=========>....................] - ETA: 9s - loss: 2.0712 - masked_accuracy: 0.2547 45/124 [=========>....................] - ETA: 9s - loss: 2.0652 - masked_accuracy: 0.2554 46/124 [==========>...................] - ETA: 9s - loss: 2.0608 - masked_accuracy: 0.2551 47/124 [==========>...................] - ETA: 9s - loss: 2.0560 - masked_accuracy: 0.2560 48/124 [==========>...................] - ETA: 9s - loss: 2.0503 - masked_accuracy: 0.2564 49/124 [==========>...................] - ETA: 9s - loss: 2.0463 - masked_accuracy: 0.2565 50/124 [===========>..................] - ETA: 8s - loss: 2.0416 - masked_accuracy: 0.2567 51/124 [===========>..................] - ETA: 8s - loss: 2.0382 - masked_accuracy: 0.2574 52/124 [===========>..................] - ETA: 8s - loss: 2.0328 - masked_accuracy: 0.2582 53/124 [===========>..................] - ETA: 8s - loss: 2.0288 - masked_accuracy: 0.2587 54/124 [============>.................] - ETA: 8s - loss: 2.0245 - masked_accuracy: 0.2593 55/124 [============>.................] - ETA: 8s - loss: 2.0210 - masked_accuracy: 0.2597 56/124 [============>.................] - ETA: 8s - loss: 2.0176 - masked_accuracy: 0.2600 57/124 [============>.................] - ETA: 8s - loss: 2.0134 - masked_accuracy: 0.2605 58/124 [=============>................] - ETA: 7s - loss: 2.0095 - masked_accuracy: 0.2609 59/124 [=============>................] - ETA: 7s - loss: 2.0052 - masked_accuracy: 0.2613 60/124 [=============>................] - ETA: 7s - loss: 2.0022 - masked_accuracy: 0.2617 61/124 [=============>................] - ETA: 7s - loss: 1.9988 - masked_accuracy: 0.2620 62/124 [==============>...............] - ETA: 7s - loss: 1.9957 - masked_accuracy: 0.2627 63/124 [==============>...............] - ETA: 7s - loss: 1.9914 - masked_accuracy: 0.2632 64/124 [==============>...............] - ETA: 7s - loss: 1.9882 - masked_accuracy: 0.2634 65/124 [==============>...............] - ETA: 7s - loss: 1.9845 - masked_accuracy: 0.2639 66/124 [==============>...............] - ETA: 6s - loss: 1.9812 - masked_accuracy: 0.2643 67/124 [===============>..............] - ETA: 6s - loss: 1.9785 - masked_accuracy: 0.2647 68/124 [===============>..............] - ETA: 6s - loss: 1.9763 - masked_accuracy: 0.2650 69/124 [===============>..............] - ETA: 6s - loss: 1.9738 - masked_accuracy: 0.2652 70/124 [===============>..............] - ETA: 6s - loss: 1.9706 - masked_accuracy: 0.2654 71/124 [================>.............] - ETA: 6s - loss: 1.9681 - masked_accuracy: 0.2654 72/124 [================>.............] - ETA: 6s - loss: 1.9655 - masked_accuracy: 0.2657 73/124 [================>.............] - ETA: 6s - loss: 1.9623 - masked_accuracy: 0.2659 74/124 [================>.............] - ETA: 5s - loss: 1.9599 - masked_accuracy: 0.2661 75/124 [=================>............] - ETA: 5s - loss: 1.9582 - masked_accuracy: 0.2663 76/124 [=================>............] - ETA: 5s - loss: 1.9558 - masked_accuracy: 0.2663 77/124 [=================>............] - ETA: 5s - loss: 1.9538 - masked_accuracy: 0.2662 78/124 [=================>............] - ETA: 5s - loss: 1.9515 - masked_accuracy: 0.2665 79/124 [==================>...........] - ETA: 5s - loss: 1.9493 - masked_accuracy: 0.2669 80/124 [==================>...........] - ETA: 5s - loss: 1.9469 - masked_accuracy: 0.2672 81/124 [==================>...........] - ETA: 5s - loss: 1.9441 - masked_accuracy: 0.2676 82/124 [==================>...........] - ETA: 5s - loss: 1.9415 - masked_accuracy: 0.2679 83/124 [===================>..........] - ETA: 4s - loss: 1.9401 - masked_accuracy: 0.2678 84/124 [===================>..........] - ETA: 4s - loss: 1.9385 - masked_accuracy: 0.2678 85/124 [===================>..........] - ETA: 4s - loss: 1.9367 - masked_accuracy: 0.2680 86/124 [===================>..........] - ETA: 4s - loss: 1.9350 - masked_accuracy: 0.2683 87/124 [====================>.........] - ETA: 4s - loss: 1.9334 - masked_accuracy: 0.2683 88/124 [====================>.........] - ETA: 4s - loss: 1.9314 - masked_accuracy: 0.2684 89/124 [====================>.........] - ETA: 4s - loss: 1.9300 - masked_accuracy: 0.2684 90/124 [====================>.........] - ETA: 4s - loss: 1.9285 - masked_accuracy: 0.2686 91/124 [=====================>........] - ETA: 3s - loss: 1.9266 - masked_accuracy: 0.2688 92/124 [=====================>........] - ETA: 3s - loss: 1.9244 - masked_accuracy: 0.2692 93/124 [=====================>........] - ETA: 3s - loss: 1.9231 - masked_accuracy: 0.2692 94/124 [=====================>........] - ETA: 3s - loss: 1.9211 - masked_accuracy: 0.2693 95/124 [=====================>........] - ETA: 3s - loss: 1.9191 - masked_accuracy: 0.2696 96/124 [======================>.......] - ETA: 3s - loss: 1.9181 - masked_accuracy: 0.2696 97/124 [======================>.......] - ETA: 3s - loss: 1.9162 - masked_accuracy: 0.2697 98/124 [======================>.......] - ETA: 3s - loss: 1.9144 - masked_accuracy: 0.2698 99/124 [======================>.......] - ETA: 2s - loss: 1.9132 - masked_accuracy: 0.2700100/124 [=======================>......] - ETA: 2s - loss: 1.9120 - masked_accuracy: 0.2700101/124 [=======================>......] - ETA: 2s - loss: 1.9106 - masked_accuracy: 0.2702102/124 [=======================>......] - ETA: 2s - loss: 1.9091 - masked_accuracy: 0.2703103/124 [=======================>......] - ETA: 2s - loss: 1.9075 - masked_accuracy: 0.2704104/124 [========================>.....] - ETA: 2s - loss: 1.9060 - masked_accuracy: 0.2704105/124 [========================>.....] - ETA: 2s - loss: 1.9045 - masked_accuracy: 0.2707106/124 [========================>.....] - ETA: 2s - loss: 1.9030 - masked_accuracy: 0.2708107/124 [========================>.....] - ETA: 2s - loss: 1.9020 - masked_accuracy: 0.2709108/124 [=========================>....] - ETA: 1s - loss: 1.9009 - masked_accuracy: 0.2713109/124 [=========================>....] - ETA: 1s - loss: 1.8993 - masked_accuracy: 0.2716110/124 [=========================>....] - ETA: 1s - loss: 1.8979 - masked_accuracy: 0.2719111/124 [=========================>....] - ETA: 1s - loss: 1.8968 - masked_accuracy: 0.2720112/124 [==========================>...] - ETA: 1s - loss: 1.8955 - masked_accuracy: 0.2722113/124 [==========================>...] - ETA: 1s - loss: 1.8945 - masked_accuracy: 0.2723114/124 [==========================>...] - ETA: 1s - loss: 1.8932 - masked_accuracy: 0.2723115/124 [==========================>...] - ETA: 1s - loss: 1.8919 - masked_accuracy: 0.2723116/124 [===========================>..] - ETA: 0s - loss: 1.8906 - masked_accuracy: 0.2726117/124 [===========================>..] - ETA: 0s - loss: 1.8894 - masked_accuracy: 0.2727118/124 [===========================>..] - ETA: 0s - loss: 1.8885 - masked_accuracy: 0.2726119/124 [===========================>..] - ETA: 0s - loss: 1.8873 - masked_accuracy: 0.2726120/124 [============================>.] - ETA: 0s - loss: 1.8868 - masked_accuracy: 0.2726121/124 [============================>.] - ETA: 0s - loss: 1.8856 - masked_accuracy: 0.2727122/124 [============================>.] - ETA: 0s - loss: 1.8848 - masked_accuracy: 0.2728123/124 [============================>.] - ETA: 0s - loss: 1.8840 - masked_accuracy: 0.2729124/124 [==============================] - ETA: 0s - loss: 1.8829 - masked_accuracy: 0.2729124/124 [==============================] - 100s 237ms/step - loss: 1.8829 - masked_accuracy: 0.2729 - val_loss: 1.7383 - val_masked_accuracy: 0.2835
Epoch 2/200
  1/124 [..............................] - ETA: 24s - loss: 1.7960 - masked_accuracy: 0.2771  2/124 [..............................] - ETA: 19s - loss: 1.7911 - masked_accuracy: 0.2782  3/124 [..............................] - ETA: 17s - loss: 1.7606 - masked_accuracy: 0.2858  4/124 [..............................] - ETA: 15s - loss: 1.7668 - masked_accuracy: 0.2821  5/124 [>.............................] - ETA: 15s - loss: 1.7583 - masked_accuracy: 0.2853  6/124 [>.............................] - ETA: 14s - loss: 1.7492 - masked_accuracy: 0.2895  7/124 [>.............................] - ETA: 14s - loss: 1.7498 - masked_accuracy: 0.2875  8/124 [>.............................] - ETA: 14s - loss: 1.7501 - masked_accuracy: 0.2842  9/124 [=>............................] - ETA: 14s - loss: 1.7452 - masked_accuracy: 0.2869 10/124 [=>............................] - ETA: 13s - loss: 1.7406 - masked_accuracy: 0.2884 11/124 [=>............................] - ETA: 13s - loss: 1.7371 - masked_accuracy: 0.2883 12/124 [=>............................] - ETA: 13s - loss: 1.7416 - masked_accuracy: 0.2872 13/124 [==>...........................] - ETA: 13s - loss: 1.7441 - masked_accuracy: 0.2867 14/124 [==>...........................] - ETA: 13s - loss: 1.7451 - masked_accuracy: 0.2859 15/124 [==>...........................] - ETA: 13s - loss: 1.7449 - masked_accuracy: 0.2861 16/124 [==>...........................] - ETA: 12s - loss: 1.7411 - masked_accuracy: 0.2857 17/124 [===>..........................] - ETA: 12s - loss: 1.7402 - masked_accuracy: 0.2865 18/124 [===>..........................] - ETA: 12s - loss: 1.7434 - masked_accuracy: 0.2844 19/124 [===>..........................] - ETA: 12s - loss: 1.7419 - masked_accuracy: 0.2841 20/124 [===>..........................] - ETA: 12s - loss: 1.7413 - masked_accuracy: 0.2845 21/124 [====>.........................] - ETA: 12s - loss: 1.7404 - masked_accuracy: 0.2850 22/124 [====>.........................] - ETA: 12s - loss: 1.7415 - masked_accuracy: 0.2850 23/124 [====>.........................] - ETA: 12s - loss: 1.7393 - masked_accuracy: 0.2854 24/124 [====>.........................] - ETA: 11s - loss: 1.7358 - masked_accuracy: 0.2861 25/124 [=====>........................] - ETA: 11s - loss: 1.7348 - masked_accuracy: 0.2870 26/124 [=====>........................] - ETA: 11s - loss: 1.7348 - masked_accuracy: 0.2861 27/124 [=====>........................] - ETA: 11s - loss: 1.7346 - masked_accuracy: 0.2862 28/124 [=====>........................] - ETA: 11s - loss: 1.7329 - masked_accuracy: 0.2869 29/124 [======>.......................] - ETA: 11s - loss: 1.7318 - masked_accuracy: 0.2873 30/124 [======>.......................] - ETA: 11s - loss: 1.7314 - masked_accuracy: 0.2870 31/124 [======>.......................] - ETA: 11s - loss: 1.7316 - masked_accuracy: 0.2868 32/124 [======>.......................] - ETA: 10s - loss: 1.7317 - masked_accuracy: 0.2868 33/124 [======>.......................] - ETA: 10s - loss: 1.7297 - masked_accuracy: 0.2873 34/124 [=======>......................] - ETA: 10s - loss: 1.7301 - masked_accuracy: 0.2874 35/124 [=======>......................] - ETA: 10s - loss: 1.7286 - masked_accuracy: 0.2871 36/124 [=======>......................] - ETA: 10s - loss: 1.7273 - masked_accuracy: 0.2872 37/124 [=======>......................] - ETA: 10s - loss: 1.7269 - masked_accuracy: 0.2869 38/124 [========>.....................] - ETA: 10s - loss: 1.7249 - masked_accuracy: 0.2874 39/124 [========>.....................] - ETA: 10s - loss: 1.7236 - masked_accuracy: 0.2878 40/124 [========>.....................] - ETA: 9s - loss: 1.7228 - masked_accuracy: 0.2881  41/124 [========>.....................] - ETA: 9s - loss: 1.7235 - masked_accuracy: 0.2882 42/124 [=========>....................] - ETA: 9s - loss: 1.7219 - masked_accuracy: 0.2881 43/124 [=========>....................] - ETA: 9s - loss: 1.7232 - masked_accuracy: 0.2875 44/124 [=========>....................] - ETA: 9s - loss: 1.7221 - masked_accuracy: 0.2879 45/124 [=========>....................] - ETA: 9s - loss: 1.7221 - masked_accuracy: 0.2879 46/124 [==========>...................] - ETA: 9s - loss: 1.7211 - masked_accuracy: 0.2880 47/124 [==========>...................] - ETA: 9s - loss: 1.7210 - masked_accuracy: 0.2879 48/124 [==========>...................] - ETA: 8s - loss: 1.7202 - masked_accuracy: 0.2880 49/124 [==========>...................] - ETA: 8s - loss: 1.7197 - masked_accuracy: 0.2884 50/124 [===========>..................] - ETA: 8s - loss: 1.7182 - masked_accuracy: 0.2885 51/124 [===========>..................] - ETA: 8s - loss: 1.7183 - masked_accuracy: 0.2884 52/124 [===========>..................] - ETA: 8s - loss: 1.7178 - masked_accuracy: 0.2884 53/124 [===========>..................] - ETA: 8s - loss: 1.7156 - masked_accuracy: 0.2885 54/124 [============>.................] - ETA: 8s - loss: 1.7152 - masked_accuracy: 0.2886 55/124 [============>.................] - ETA: 8s - loss: 1.7146 - masked_accuracy: 0.2888 56/124 [============>.................] - ETA: 8s - loss: 1.7140 - masked_accuracy: 0.2887 57/124 [============>.................] - ETA: 7s - loss: 1.7139 - masked_accuracy: 0.2887 58/124 [=============>................] - ETA: 7s - loss: 1.7131 - masked_accuracy: 0.2888 59/124 [=============>................] - ETA: 7s - loss: 1.7123 - masked_accuracy: 0.2891 60/124 [=============>................] - ETA: 7s - loss: 1.7107 - masked_accuracy: 0.2894 61/124 [=============>................] - ETA: 7s - loss: 1.7099 - masked_accuracy: 0.2895 62/124 [==============>...............] - ETA: 7s - loss: 1.7084 - masked_accuracy: 0.2898 63/124 [==============>...............] - ETA: 7s - loss: 1.7072 - masked_accuracy: 0.2901 64/124 [==============>...............] - ETA: 7s - loss: 1.7054 - masked_accuracy: 0.2906 65/124 [==============>...............] - ETA: 6s - loss: 1.7048 - masked_accuracy: 0.2907 66/124 [==============>...............] - ETA: 6s - loss: 1.7039 - masked_accuracy: 0.2910 67/124 [===============>..............] - ETA: 6s - loss: 1.7019 - masked_accuracy: 0.2913 68/124 [===============>..............] - ETA: 6s - loss: 1.7008 - masked_accuracy: 0.2917 69/124 [===============>..............] - ETA: 6s - loss: 1.6993 - masked_accuracy: 0.2922 70/124 [===============>..............] - ETA: 6s - loss: 1.6979 - masked_accuracy: 0.2927 71/124 [================>.............] - ETA: 6s - loss: 1.6961 - masked_accuracy: 0.2932 72/124 [================>.............] - ETA: 6s - loss: 1.6950 - masked_accuracy: 0.2934 73/124 [================>.............] - ETA: 6s - loss: 1.6934 - masked_accuracy: 0.2938 74/124 [================>.............] - ETA: 5s - loss: 1.6918 - masked_accuracy: 0.2942 75/124 [=================>............] - ETA: 5s - loss: 1.6906 - masked_accuracy: 0.2942 76/124 [=================>............] - ETA: 5s - loss: 1.6887 - masked_accuracy: 0.2946 77/124 [=================>............] - ETA: 5s - loss: 1.6877 - masked_accuracy: 0.2950 78/124 [=================>............] - ETA: 5s - loss: 1.6859 - masked_accuracy: 0.2954 79/124 [==================>...........] - ETA: 5s - loss: 1.6842 - masked_accuracy: 0.2957 80/124 [==================>...........] - ETA: 5s - loss: 1.6829 - masked_accuracy: 0.2959 81/124 [==================>...........] - ETA: 5s - loss: 1.6821 - masked_accuracy: 0.2961 82/124 [==================>...........] - ETA: 4s - loss: 1.6809 - masked_accuracy: 0.2962 83/124 [===================>..........] - ETA: 4s - loss: 1.6796 - masked_accuracy: 0.2964 84/124 [===================>..........] - ETA: 4s - loss: 1.6778 - masked_accuracy: 0.2969 85/124 [===================>..........] - ETA: 4s - loss: 1.6764 - masked_accuracy: 0.2972 86/124 [===================>..........] - ETA: 4s - loss: 1.6756 - masked_accuracy: 0.2974 87/124 [====================>.........] - ETA: 4s - loss: 1.6749 - masked_accuracy: 0.2977 88/124 [====================>.........] - ETA: 4s - loss: 1.6736 - masked_accuracy: 0.2980 89/124 [====================>.........] - ETA: 4s - loss: 1.6721 - masked_accuracy: 0.2986 90/124 [====================>.........] - ETA: 4s - loss: 1.6713 - masked_accuracy: 0.2986 91/124 [=====================>........] - ETA: 3s - loss: 1.6695 - masked_accuracy: 0.2990 92/124 [=====================>........] - ETA: 3s - loss: 1.6684 - masked_accuracy: 0.2994 93/124 [=====================>........] - ETA: 3s - loss: 1.6670 - masked_accuracy: 0.2997 94/124 [=====================>........] - ETA: 3s - loss: 1.6660 - masked_accuracy: 0.2999 95/124 [=====================>........] - ETA: 3s - loss: 1.6648 - masked_accuracy: 0.3003 96/124 [======================>.......] - ETA: 3s - loss: 1.6635 - masked_accuracy: 0.3005 97/124 [======================>.......] - ETA: 3s - loss: 1.6619 - masked_accuracy: 0.3008 98/124 [======================>.......] - ETA: 3s - loss: 1.6607 - masked_accuracy: 0.3010 99/124 [======================>.......] - ETA: 2s - loss: 1.6593 - masked_accuracy: 0.3012100/124 [=======================>......] - ETA: 2s - loss: 1.6584 - masked_accuracy: 0.3015101/124 [=======================>......] - ETA: 2s - loss: 1.6571 - masked_accuracy: 0.3020102/124 [=======================>......] - ETA: 2s - loss: 1.6559 - masked_accuracy: 0.3023103/124 [=======================>......] - ETA: 2s - loss: 1.6547 - masked_accuracy: 0.3025104/124 [========================>.....] - ETA: 2s - loss: 1.6531 - masked_accuracy: 0.3029105/124 [========================>.....] - ETA: 2s - loss: 1.6515 - masked_accuracy: 0.3035106/124 [========================>.....] - ETA: 2s - loss: 1.6505 - masked_accuracy: 0.3038107/124 [========================>.....] - ETA: 2s - loss: 1.6490 - masked_accuracy: 0.3041108/124 [=========================>....] - ETA: 1s - loss: 1.6476 - masked_accuracy: 0.3046109/124 [=========================>....] - ETA: 1s - loss: 1.6462 - masked_accuracy: 0.3048110/124 [=========================>....] - ETA: 1s - loss: 1.6451 - masked_accuracy: 0.3051111/124 [=========================>....] - ETA: 1s - loss: 1.6437 - masked_accuracy: 0.3054112/124 [==========================>...] - ETA: 1s - loss: 1.6432 - masked_accuracy: 0.3055113/124 [==========================>...] - ETA: 1s - loss: 1.6421 - masked_accuracy: 0.3059114/124 [==========================>...] - ETA: 1s - loss: 1.6409 - masked_accuracy: 0.3063115/124 [==========================>...] - ETA: 1s - loss: 1.6394 - masked_accuracy: 0.3067116/124 [===========================>..] - ETA: 0s - loss: 1.6384 - masked_accuracy: 0.3068117/124 [===========================>..] - ETA: 0s - loss: 1.6370 - masked_accuracy: 0.3071118/124 [===========================>..] - ETA: 0s - loss: 1.6356 - masked_accuracy: 0.3075119/124 [===========================>..] - ETA: 0s - loss: 1.6348 - masked_accuracy: 0.3076120/124 [============================>.] - ETA: 0s - loss: 1.6341 - masked_accuracy: 0.3078121/124 [============================>.] - ETA: 0s - loss: 1.6333 - masked_accuracy: 0.3079122/124 [============================>.] - ETA: 0s - loss: 1.6323 - masked_accuracy: 0.3082123/124 [============================>.] - ETA: 0s - loss: 1.6311 - masked_accuracy: 0.3084