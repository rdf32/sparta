Loading analytics/1.04.0000.202011101237_0264
  Loading requirement: crayai/0.6.0000.202008211107_0069
Segmentation Models: using `tf.keras` framework.
Loading data
Training -> Samples: 127905,  Targets: 127905
Validation -> Samples: 127905,  Targets: 127905
Steps per Training Epoch -> 124
Steps per Validation Epoch -> 124
['GPU:0', 'GPU:1', 'GPU:2', 'GPU:3']
Compiling and returning model
Model: "TransformerEncoderMLP"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 19, 18)]     0           []                               
                                                                                                  
 positional_embedding (Position  (None, 19, 18)      0           ['input_1[0][0]']                
 alEmbedding)                                                                                     
                                                                                                  
 dropout (Dropout)              (None, 19, 18)       0           ['positional_embedding[0][0]']   
                                                                                                  
 layer_normalization (LayerNorm  (None, 19, 18)      36          ['dropout[0][0]']                
 alization)                                                                                       
                                                                                                  
 multi_head_attention (MultiHea  (None, 19, 18)      8118        ['layer_normalization[0][0]',    
 dAttention)                                                      'layer_normalization[0][0]',    
                                                                  'layer_normalization[0][0]']    
                                                                                                  
 add (Add)                      (None, 19, 18)       0           ['dropout[0][0]',                
                                                                  'multi_head_attention[0][0]']   
                                                                                                  
 layer_normalization_1 (LayerNo  (None, 19, 18)      36          ['add[0][0]']                    
 rmalization)                                                                                     
                                                                                                  
 dense (Dense)                  (None, 19, 72)       1368        ['layer_normalization_1[0][0]']  
                                                                                                  
 dense_1 (Dense)                (None, 19, 18)       1314        ['dense[0][0]']                  
                                                                                                  
 dropout_1 (Dropout)            (None, 19, 18)       0           ['dense_1[0][0]']                
                                                                                                  
 add_1 (Add)                    (None, 19, 18)       0           ['add[0][0]',                    
                                                                  'dropout_1[0][0]']              
                                                                                                  
 layer_normalization_2 (LayerNo  (None, 19, 18)      36          ['add_1[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_1 (MultiH  (None, 19, 18)      8118        ['layer_normalization_2[0][0]',  
 eadAttention)                                                    'layer_normalization_2[0][0]',  
                                                                  'layer_normalization_2[0][0]']  
                                                                                                  
 add_2 (Add)                    (None, 19, 18)       0           ['add_1[0][0]',                  
                                                                  'multi_head_attention_1[0][0]'] 
                                                                                                  
 layer_normalization_3 (LayerNo  (None, 19, 18)      36          ['add_2[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_2 (Dense)                (None, 19, 72)       1368        ['layer_normalization_3[0][0]']  
                                                                                                  
 dense_3 (Dense)                (None, 19, 18)       1314        ['dense_2[0][0]']                
                                                                                                  
 dropout_2 (Dropout)            (None, 19, 18)       0           ['dense_3[0][0]']                
                                                                                                  
 add_3 (Add)                    (None, 19, 18)       0           ['add_2[0][0]',                  
                                                                  'dropout_2[0][0]']              
                                                                                                  
 layer_normalization_4 (LayerNo  (None, 19, 18)      36          ['add_3[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_2 (MultiH  (None, 19, 18)      8118        ['layer_normalization_4[0][0]',  
 eadAttention)                                                    'layer_normalization_4[0][0]',  
                                                                  'layer_normalization_4[0][0]']  
                                                                                                  
 add_4 (Add)                    (None, 19, 18)       0           ['add_3[0][0]',                  
                                                                  'multi_head_attention_2[0][0]'] 
                                                                                                  
 layer_normalization_5 (LayerNo  (None, 19, 18)      36          ['add_4[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_4 (Dense)                (None, 19, 72)       1368        ['layer_normalization_5[0][0]']  
                                                                                                  
 dense_5 (Dense)                (None, 19, 18)       1314        ['dense_4[0][0]']                
                                                                                                  
 dropout_3 (Dropout)            (None, 19, 18)       0           ['dense_5[0][0]']                
                                                                                                  
 add_5 (Add)                    (None, 19, 18)       0           ['add_4[0][0]',                  
                                                                  'dropout_3[0][0]']              
                                                                                                  
 layer_normalization_6 (LayerNo  (None, 19, 18)      36          ['add_5[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_3 (MultiH  (None, 19, 18)      8118        ['layer_normalization_6[0][0]',  
 eadAttention)                                                    'layer_normalization_6[0][0]',  
                                                                  'layer_normalization_6[0][0]']  
                                                                                                  
 add_6 (Add)                    (None, 19, 18)       0           ['add_5[0][0]',                  
                                                                  'multi_head_attention_3[0][0]'] 
                                                                                                  
 layer_normalization_7 (LayerNo  (None, 19, 18)      36          ['add_6[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_6 (Dense)                (None, 19, 72)       1368        ['layer_normalization_7[0][0]']  
                                                                                                  
 dense_7 (Dense)                (None, 19, 18)       1314        ['dense_6[0][0]']                
                                                                                                  
 dropout_4 (Dropout)            (None, 19, 18)       0           ['dense_7[0][0]']                
                                                                                                  
 add_7 (Add)                    (None, 19, 18)       0           ['add_6[0][0]',                  
                                                                  'dropout_4[0][0]']              
                                                                                                  
 layer_normalization_8 (LayerNo  (None, 19, 18)      36          ['add_7[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_4 (MultiH  (None, 19, 18)      8118        ['layer_normalization_8[0][0]',  
 eadAttention)                                                    'layer_normalization_8[0][0]',  
                                                                  'layer_normalization_8[0][0]']  
                                                                                                  
 add_8 (Add)                    (None, 19, 18)       0           ['add_7[0][0]',                  
                                                                  'multi_head_attention_4[0][0]'] 
                                                                                                  
 layer_normalization_9 (LayerNo  (None, 19, 18)      36          ['add_8[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_8 (Dense)                (None, 19, 72)       1368        ['layer_normalization_9[0][0]']  
                                                                                                  
 dense_9 (Dense)                (None, 19, 18)       1314        ['dense_8[0][0]']                
                                                                                                  
 dropout_5 (Dropout)            (None, 19, 18)       0           ['dense_9[0][0]']                
                                                                                                  
 add_9 (Add)                    (None, 19, 18)       0           ['add_8[0][0]',                  
                                                                  'dropout_5[0][0]']              
                                                                                                  
 layer_normalization_10 (LayerN  (None, 19, 18)      36          ['add_9[0][0]']                  
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_5 (MultiH  (None, 19, 18)      8118        ['layer_normalization_10[0][0]', 
 eadAttention)                                                    'layer_normalization_10[0][0]', 
                                                                  'layer_normalization_10[0][0]'] 
                                                                                                  
 add_10 (Add)                   (None, 19, 18)       0           ['add_9[0][0]',                  
                                                                  'multi_head_attention_5[0][0]'] 
                                                                                                  
 layer_normalization_11 (LayerN  (None, 19, 18)      36          ['add_10[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 dense_10 (Dense)               (None, 19, 72)       1368        ['layer_normalization_11[0][0]'] 
                                                                                                  
 dense_11 (Dense)               (None, 19, 18)       1314        ['dense_10[0][0]']               
                                                                                                  
 dropout_6 (Dropout)            (None, 19, 18)       0           ['dense_11[0][0]']               
                                                                                                  
 add_11 (Add)                   (None, 19, 18)       0           ['add_10[0][0]',                 
                                                                  'dropout_6[0][0]']              
                                                                                                  
 dense_12 (Dense)               (None, 19, 128)      2432        ['add_11[0][0]']                 
                                                                                                  
 dense_13 (Dense)               (None, 19, 256)      33024       ['dense_12[0][0]']               
                                                                                                  
 dense_14 (Dense)               (None, 19, 512)      131584      ['dense_13[0][0]']               
                                                                                                  
 dense_15 (Dense)               (None, 19, 18)       9234        ['dense_14[0][0]']               
                                                                                                  
==================================================================================================
Total params: 241,506
Trainable params: 241,506
Non-trainable params: 0
__________________________________________________________________________________________________
Training model: transformer_encoder_mlp
Using tf.Dataset
Epoch 1/200
  1/124 [..............................] - ETA: 2:25:02 - loss: 2.6506 - masked_accuracy: 0.0039  2/124 [..............................] - ETA: 21s - loss: 2.6137 - masked_accuracy: 0.0041      3/124 [..............................] - ETA: 18s - loss: 2.5711 - masked_accuracy: 0.0061  4/124 [..............................] - ETA: 17s - loss: 2.5476 - masked_accuracy: 0.0120  5/124 [>.............................] - ETA: 16s - loss: 2.5177 - masked_accuracy: 0.0316  6/124 [>.............................] - ETA: 15s - loss: 2.4824 - masked_accuracy: 0.0638  7/124 [>.............................] - ETA: 15s - loss: 2.4466 - masked_accuracy: 0.0961  8/124 [>.............................] - ETA: 15s - loss: 2.4132 - masked_accuracy: 0.1221  9/124 [=>............................] - ETA: 14s - loss: 2.3838 - masked_accuracy: 0.1412 10/124 [=>............................] - ETA: 15s - loss: 2.3560 - masked_accuracy: 0.1554 11/124 [=>............................] - ETA: 15s - loss: 2.3288 - masked_accuracy: 0.1663 12/124 [=>............................] - ETA: 14s - loss: 2.3006 - masked_accuracy: 0.1760 13/124 [==>...........................] - ETA: 14s - loss: 2.2749 - masked_accuracy: 0.1832 14/124 [==>...........................] - ETA: 14s - loss: 2.2483 - masked_accuracy: 0.1910 15/124 [==>...........................] - ETA: 14s - loss: 2.2221 - masked_accuracy: 0.1973 16/124 [==>...........................] - ETA: 14s - loss: 2.1972 - masked_accuracy: 0.2036 17/124 [===>..........................] - ETA: 14s - loss: 2.1743 - masked_accuracy: 0.2087 18/124 [===>..........................] - ETA: 13s - loss: 2.1482 - masked_accuracy: 0.2159 19/124 [===>..........................] - ETA: 13s - loss: 2.1267 - masked_accuracy: 0.2208 20/124 [===>..........................] - ETA: 13s - loss: 2.1042 - masked_accuracy: 0.2277 21/124 [====>.........................] - ETA: 13s - loss: 2.0839 - masked_accuracy: 0.2346 22/124 [====>.........................] - ETA: 13s - loss: 2.0631 - masked_accuracy: 0.2410 23/124 [====>.........................] - ETA: 13s - loss: 2.0445 - masked_accuracy: 0.2464 24/124 [====>.........................] - ETA: 13s - loss: 2.0238 - masked_accuracy: 0.2530 25/124 [=====>........................] - ETA: 12s - loss: 2.0046 - masked_accuracy: 0.2589 26/124 [=====>........................] - ETA: 12s - loss: 1.9869 - masked_accuracy: 0.2641 27/124 [=====>........................] - ETA: 12s - loss: 1.9675 - masked_accuracy: 0.2709 28/124 [=====>........................] - ETA: 12s - loss: 1.9504 - masked_accuracy: 0.2770 29/124 [======>.......................] - ETA: 12s - loss: 1.9332 - masked_accuracy: 0.2834 30/124 [======>.......................] - ETA: 12s - loss: 1.9183 - masked_accuracy: 0.2892 31/124 [======>.......................] - ETA: 11s - loss: 1.9003 - masked_accuracy: 0.2962 32/124 [======>.......................] - ETA: 11s - loss: 1.8856 - masked_accuracy: 0.3019 33/124 [======>.......................] - ETA: 11s - loss: 1.8707 - masked_accuracy: 0.3078 34/124 [=======>......................] - ETA: 11s - loss: 1.8544 - masked_accuracy: 0.3144 35/124 [=======>......................] - ETA: 11s - loss: 1.8396 - masked_accuracy: 0.3205 36/124 [=======>......................] - ETA: 11s - loss: 1.8254 - masked_accuracy: 0.3263 37/124 [=======>......................] - ETA: 11s - loss: 1.8113 - masked_accuracy: 0.3320 38/124 [========>.....................] - ETA: 11s - loss: 1.8004 - masked_accuracy: 0.3365 39/124 [========>.....................] - ETA: 11s - loss: 1.7870 - masked_accuracy: 0.3417 40/124 [========>.....................] - ETA: 10s - loss: 1.7732 - masked_accuracy: 0.3474 41/124 [========>.....................] - ETA: 10s - loss: 1.7613 - masked_accuracy: 0.3522 42/124 [=========>....................] - ETA: 10s - loss: 1.7497 - masked_accuracy: 0.3567 43/124 [=========>....................] - ETA: 10s - loss: 1.7381 - masked_accuracy: 0.3611 44/124 [=========>....................] - ETA: 10s - loss: 1.7254 - masked_accuracy: 0.3661 45/124 [=========>....................] - ETA: 10s - loss: 1.7133 - masked_accuracy: 0.3705 46/124 [==========>...................] - ETA: 10s - loss: 1.7029 - masked_accuracy: 0.3744 47/124 [==========>...................] - ETA: 9s - loss: 1.6923 - masked_accuracy: 0.3783  48/124 [==========>...................] - ETA: 9s - loss: 1.6805 - masked_accuracy: 0.3827 49/124 [==========>...................] - ETA: 9s - loss: 1.6702 - masked_accuracy: 0.3864 50/124 [===========>..................] - ETA: 9s - loss: 1.6590 - masked_accuracy: 0.3903 51/124 [===========>..................] - ETA: 9s - loss: 1.6494 - masked_accuracy: 0.3939 52/124 [===========>..................] - ETA: 9s - loss: 1.6381 - masked_accuracy: 0.3979 53/124 [===========>..................] - ETA: 9s - loss: 1.6279 - masked_accuracy: 0.4013 54/124 [============>.................] - ETA: 8s - loss: 1.6180 - masked_accuracy: 0.4048 55/124 [============>.................] - ETA: 8s - loss: 1.6092 - masked_accuracy: 0.4080 56/124 [============>.................] - ETA: 8s - loss: 1.5996 - masked_accuracy: 0.4113 57/124 [============>.................] - ETA: 8s - loss: 1.5894 - masked_accuracy: 0.4150 58/124 [=============>................] - ETA: 8s - loss: 1.5796 - masked_accuracy: 0.4181 59/124 [=============>................] - ETA: 8s - loss: 1.5697 - masked_accuracy: 0.4212 60/124 [=============>................] - ETA: 8s - loss: 1.5607 - masked_accuracy: 0.4243 61/124 [=============>................] - ETA: 8s - loss: 1.5513 - masked_accuracy: 0.4273 62/124 [==============>...............] - ETA: 7s - loss: 1.5429 - masked_accuracy: 0.4299 63/124 [==============>...............] - ETA: 7s - loss: 1.5338 - masked_accuracy: 0.4327 64/124 [==============>...............] - ETA: 7s - loss: 1.5252 - masked_accuracy: 0.4353 65/124 [==============>...............] - ETA: 7s - loss: 1.5167 - masked_accuracy: 0.4379 66/124 [==============>...............] - ETA: 7s - loss: 1.5084 - masked_accuracy: 0.4405 67/124 [===============>..............] - ETA: 7s - loss: 1.5003 - masked_accuracy: 0.4430 68/124 [===============>..............] - ETA: 7s - loss: 1.4926 - masked_accuracy: 0.4454 69/124 [===============>..............] - ETA: 7s - loss: 1.4857 - masked_accuracy: 0.4475 70/124 [===============>..............] - ETA: 6s - loss: 1.4781 - masked_accuracy: 0.4497 71/124 [================>.............] - ETA: 6s - loss: 1.4708 - masked_accuracy: 0.4519 72/124 [================>.............] - ETA: 6s - loss: 1.4632 - masked_accuracy: 0.4541 73/124 [================>.............] - ETA: 6s - loss: 1.4555 - masked_accuracy: 0.4566 74/124 [================>.............] - ETA: 6s - loss: 1.4477 - masked_accuracy: 0.4588 75/124 [=================>............] - ETA: 6s - loss: 1.4414 - masked_accuracy: 0.4605 76/124 [=================>............] - ETA: 6s - loss: 1.4348 - masked_accuracy: 0.4624 77/124 [=================>............] - ETA: 6s - loss: 1.4285 - masked_accuracy: 0.4642 78/124 [=================>............] - ETA: 5s - loss: 1.4218 - masked_accuracy: 0.4662 79/124 [==================>...........] - ETA: 5s - loss: 1.4154 - masked_accuracy: 0.4681 80/124 [==================>...........] - ETA: 5s - loss: 1.4089 - masked_accuracy: 0.4699 81/124 [==================>...........] - ETA: 5s - loss: 1.4022 - masked_accuracy: 0.4719 82/124 [==================>...........] - ETA: 5s - loss: 1.3953 - masked_accuracy: 0.4741 83/124 [===================>..........] - ETA: 5s - loss: 1.3898 - masked_accuracy: 0.4754 84/124 [===================>..........] - ETA: 5s - loss: 1.3838 - masked_accuracy: 0.4772 85/124 [===================>..........] - ETA: 4s - loss: 1.3779 - masked_accuracy: 0.4788 86/124 [===================>..........] - ETA: 4s - loss: 1.3724 - masked_accuracy: 0.4804 87/124 [====================>.........] - ETA: 4s - loss: 1.3665 - masked_accuracy: 0.4820 88/124 [====================>.........] - ETA: 4s - loss: 1.3609 - masked_accuracy: 0.4835 89/124 [====================>.........] - ETA: 4s - loss: 1.3559 - masked_accuracy: 0.4849 90/124 [====================>.........] - ETA: 4s - loss: 1.3509 - masked_accuracy: 0.4862 91/124 [=====================>........] - ETA: 4s - loss: 1.3451 - masked_accuracy: 0.4877 92/124 [=====================>........] - ETA: 4s - loss: 1.3389 - masked_accuracy: 0.4896 93/124 [=====================>........] - ETA: 3s - loss: 1.3342 - masked_accuracy: 0.4907 94/124 [=====================>........] - ETA: 3s - loss: 1.3285 - masked_accuracy: 0.4923 95/124 [=====================>........] - ETA: 3s - loss: 1.3234 - masked_accuracy: 0.4937 96/124 [======================>.......] - ETA: 3s - loss: 1.3188 - masked_accuracy: 0.4949 97/124 [======================>.......] - ETA: 3s - loss: 1.3133 - masked_accuracy: 0.4964 98/124 [======================>.......] - ETA: 3s - loss: 1.3083 - masked_accuracy: 0.4977 99/124 [======================>.......] - ETA: 3s - loss: 1.3037 - masked_accuracy: 0.4992100/124 [=======================>......] - ETA: 3s - loss: 1.2993 - masked_accuracy: 0.5004101/124 [=======================>......] - ETA: 2s - loss: 1.2948 - masked_accuracy: 0.5015102/124 [=======================>......] - ETA: 2s - loss: 1.2904 - masked_accuracy: 0.5028103/124 [=======================>......] - ETA: 2s - loss: 1.2858 - masked_accuracy: 0.5040104/124 [========================>.....] - ETA: 2s - loss: 1.2811 - masked_accuracy: 0.5052105/124 [========================>.....] - ETA: 2s - loss: 1.2767 - masked_accuracy: 0.5062106/124 [========================>.....] - ETA: 2s - loss: 1.2723 - masked_accuracy: 0.5073107/124 [========================>.....] - ETA: 2s - loss: 1.2682 - masked_accuracy: 0.5084108/124 [=========================>....] - ETA: 2s - loss: 1.2642 - masked_accuracy: 0.5096109/124 [=========================>....] - ETA: 1s - loss: 1.2605 - masked_accuracy: 0.5105110/124 [=========================>....] - ETA: 1s - loss: 1.2565 - masked_accuracy: 0.5116111/124 [=========================>....] - ETA: 1s - loss: 1.2525 - masked_accuracy: 0.5126112/124 [==========================>...] - ETA: 1s - loss: 1.2488 - masked_accuracy: 0.5134113/124 [==========================>...] - ETA: 1s - loss: 1.2450 - masked_accuracy: 0.5144114/124 [==========================>...] - ETA: 1s - loss: 1.2411 - masked_accuracy: 0.5154115/124 [==========================>...] - ETA: 1s - loss: 1.2374 - masked_accuracy: 0.5164116/124 [===========================>..] - ETA: 1s - loss: 1.2334 - masked_accuracy: 0.5176117/124 [===========================>..] - ETA: 0s - loss: 1.2296 - masked_accuracy: 0.5187118/124 [===========================>..] - ETA: 0s - loss: 1.2260 - masked_accuracy: 0.5195119/124 [===========================>..] - ETA: 0s - loss: 1.2222 - masked_accuracy: 0.5205120/124 [============================>.] - ETA: 0s - loss: 1.2185 - masked_accuracy: 0.5213121/124 [============================>.] - ETA: 0s - loss: 1.2151 - masked_accuracy: 0.5222122/124 [============================>.] - ETA: 0s - loss: 1.2118 - masked_accuracy: 0.5230123/124 [============================>.] - ETA: 0s - loss: 1.2083 - masked_accuracy: 0.5239124/124 [==============================] - ETA: 0s - loss: 1.2052 - masked_accuracy: 0.5246124/124 [==============================] - 101s 245ms/step - loss: 1.2052 - masked_accuracy: 0.5246 - val_loss: 0.7681 - val_masked_accuracy: 0.6318
Epoch 2/200
  1/124 [..............................] - ETA: 26s - loss: 0.8206 - masked_accuracy: 0.6328  2/124 [..............................] - ETA: 17s - loss: 0.8146 - masked_accuracy: 0.6262  3/124 [..............................] - ETA: 16s - loss: 0.7891 - masked_accuracy: 0.6317  4/124 [..............................] - ETA: 15s - loss: 0.8029 - masked_accuracy: 0.6265  5/124 [>.............................] - ETA: 15s - loss: 0.7990 - masked_accuracy: 0.6275  6/124 [>.............................] - ETA: 15s - loss: 0.7881 - masked_accuracy: 0.6330  7/124 [>.............................] - ETA: 14s - loss: 0.7905 - masked_accuracy: 0.6320  8/124 [>.............................] - ETA: 14s - loss: 0.7918 - masked_accuracy: 0.6308  9/124 [=>............................] - ETA: 14s - loss: 0.7908 - masked_accuracy: 0.6306 10/124 [=>............................] - ETA: 14s - loss: 0.7853 - masked_accuracy: 0.6323 11/124 [=>............................] - ETA: 14s - loss: 0.7845 - masked_accuracy: 0.6318 12/124 [=>............................] - ETA: 13s - loss: 0.7836 - masked_accuracy: 0.6328 13/124 [==>...........................] - ETA: 13s - loss: 0.7850 - masked_accuracy: 0.6326 14/124 [==>...........................] - ETA: 13s - loss: 0.7832 - masked_accuracy: 0.6330 15/124 [==>...........................] - ETA: 13s - loss: 0.7842 - masked_accuracy: 0.6322 16/124 [==>...........................] - ETA: 13s - loss: 0.7834 - masked_accuracy: 0.6314 17/124 [===>..........................] - ETA: 13s - loss: 0.7836 - masked_accuracy: 0.6312 18/124 [===>..........................] - ETA: 13s - loss: 0.7836 - masked_accuracy: 0.6312 19/124 [===>..........................] - ETA: 12s - loss: 0.7809 - masked_accuracy: 0.6316 20/124 [===>..........................] - ETA: 12s - loss: 0.7810 - masked_accuracy: 0.6314 21/124 [====>.........................] - ETA: 12s - loss: 0.7811 - masked_accuracy: 0.6310 22/124 [====>.........................] - ETA: 12s - loss: 0.7812 - masked_accuracy: 0.6305 23/124 [====>.........................] - ETA: 12s - loss: 0.7800 - masked_accuracy: 0.6310 24/124 [====>.........................] - ETA: 12s - loss: 0.7784 - masked_accuracy: 0.6311 25/124 [=====>........................] - ETA: 12s - loss: 0.7797 - masked_accuracy: 0.6304 26/124 [=====>........................] - ETA: 12s - loss: 0.7800 - masked_accuracy: 0.6300 27/124 [=====>........................] - ETA: 11s - loss: 0.7797 - masked_accuracy: 0.6297 28/124 [=====>........................] - ETA: 11s - loss: 0.7792 - masked_accuracy: 0.6298 29/124 [======>.......................] - ETA: 11s - loss: 0.7787 - masked_accuracy: 0.6297 30/124 [======>.......................] - ETA: 11s - loss: 0.7773 - masked_accuracy: 0.6296 31/124 [======>.......................] - ETA: 11s - loss: 0.7768 - masked_accuracy: 0.6302 32/124 [======>.......................] - ETA: 11s - loss: 0.7765 - masked_accuracy: 0.6301 33/124 [======>.......................] - ETA: 11s - loss: 0.7755 - masked_accuracy: 0.6303 34/124 [=======>......................] - ETA: 11s - loss: 0.7757 - masked_accuracy: 0.6303 35/124 [=======>......................] - ETA: 10s - loss: 0.7748 - masked_accuracy: 0.6303 36/124 [=======>......................] - ETA: 10s - loss: 0.7752 - masked_accuracy: 0.6303 37/124 [=======>......................] - ETA: 10s - loss: 0.7744 - masked_accuracy: 0.6303 38/124 [========>.....................] - ETA: 10s - loss: 0.7733 - masked_accuracy: 0.6306 39/124 [========>.....................] - ETA: 10s - loss: 0.7726 - masked_accuracy: 0.6308 40/124 [========>.....................] - ETA: 10s - loss: 0.7724 - masked_accuracy: 0.6309 41/124 [========>.....................] - ETA: 10s - loss: 0.7724 - masked_accuracy: 0.6305 42/124 [=========>....................] - ETA: 10s - loss: 0.7720 - masked_accuracy: 0.6305 43/124 [=========>....................] - ETA: 9s - loss: 0.7726 - masked_accuracy: 0.6300  44/124 [=========>....................] - ETA: 9s - loss: 0.7721 - masked_accuracy: 0.6300 45/124 [=========>....................] - ETA: 9s - loss: 0.7721 - masked_accuracy: 0.6300 46/124 [==========>...................] - ETA: 9s - loss: 0.7713 - masked_accuracy: 0.6301 47/124 [==========>...................] - ETA: 9s - loss: 0.7721 - masked_accuracy: 0.6299 48/124 [==========>...................] - ETA: 9s - loss: 0.7713 - masked_accuracy: 0.6298 49/124 [==========>...................] - ETA: 9s - loss: 0.7718 - masked_accuracy: 0.6298 50/124 [===========>..................] - ETA: 9s - loss: 0.7711 - masked_accuracy: 0.6295 51/124 [===========>..................] - ETA: 8s - loss: 0.7721 - masked_accuracy: 0.6288 52/124 [===========>..................] - ETA: 8s - loss: 0.7713 - masked_accuracy: 0.6290 53/124 [===========>..................] - ETA: 8s - loss: 0.7703 - masked_accuracy: 0.6293 54/124 [============>.................] - ETA: 8s - loss: 0.7699 - masked_accuracy: 0.6293 55/124 [============>.................] - ETA: 8s - loss: 0.7693 - masked_accuracy: 0.6295 56/124 [============>.................] - ETA: 8s - loss: 0.7689 - masked_accuracy: 0.6293 57/124 [============>.................] - ETA: 8s - loss: 0.7696 - masked_accuracy: 0.6289 58/124 [=============>................] - ETA: 8s - loss: 0.7700 - masked_accuracy: 0.6289 59/124 [=============>................] - ETA: 7s - loss: 0.7702 - masked_accuracy: 0.6286 60/124 [=============>................] - ETA: 7s - loss: 0.7696 - masked_accuracy: 0.6286 61/124 [=============>................] - ETA: 7s - loss: 0.7686 - masked_accuracy: 0.6287 62/124 [==============>...............] - ETA: 7s - loss: 0.7678 - masked_accuracy: 0.6288 63/124 [==============>...............] - ETA: 7s - loss: 0.7673 - masked_accuracy: 0.6289 64/124 [==============>...............] - ETA: 7s - loss: 0.7666 - masked_accuracy: 0.6292 65/124 [==============>...............] - ETA: 7s - loss: 0.7666 - masked_accuracy: 0.6290 66/124 [==============>...............] - ETA: 7s - loss: 0.7659 - masked_accuracy: 0.6293 67/124 [===============>..............] - ETA: 6s - loss: 0.7651 - masked_accuracy: 0.6297 68/124 [===============>..............] - ETA: 6s - loss: 0.7644 - masked_accuracy: 0.6297 69/124 [===============>..............] - ETA: 6s - loss: 0.7642 - masked_accuracy: 0.6297 70/124 [===============>..............] - ETA: 6s - loss: 0.7636 - masked_accuracy: 0.6298 71/124 [================>.............] - ETA: 6s - loss: 0.7637 - masked_accuracy: 0.6297 72/124 [================>.............] - ETA: 6s - loss: 0.7635 - masked_accuracy: 0.6297 73/124 [================>.............] - ETA: 6s - loss: 0.7626 - masked_accuracy: 0.6300 74/124 [================>.............] - ETA: 6s - loss: 0.7616 - masked_accuracy: 0.6303 75/124 [=================>............] - ETA: 5s - loss: 0.7614 - masked_accuracy: 0.6304 76/124 [=================>............] - ETA: 5s - loss: 0.7602 - masked_accuracy: 0.6307 77/124 [=================>............] - ETA: 5s - loss: 0.7596 - masked_accuracy: 0.6306 78/124 [=================>............] - ETA: 5s - loss: 0.7594 - masked_accuracy: 0.6305 79/124 [==================>...........] - ETA: 5s - loss: 0.7590 - masked_accuracy: 0.6307 80/124 [==================>...........] - ETA: 5s - loss: 0.7595 - masked_accuracy: 0.6305 81/124 [==================>...........] - ETA: 5s - loss: 0.7596 - masked_accuracy: 0.6303 82/124 [==================>...........] - ETA: 5s - loss: 0.7592 - masked_accuracy: 0.6303 83/124 [===================>..........] - ETA: 4s - loss: 0.7583 - masked_accuracy: 0.6306 84/124 [===================>..........] - ETA: 4s - loss: 0.7572 - masked_accuracy: 0.6309 85/124 [===================>..........] - ETA: 4s - loss: 0.7566 - masked_accuracy: 0.6310 86/124 [===================>..........] - ETA: 4s - loss: 0.7567 - masked_accuracy: 0.6308 87/124 [====================>.........] - ETA: 4s - loss: 0.7570 - masked_accuracy: 0.6307 88/124 [====================>.........] - ETA: 4s - loss: 0.7566 - masked_accuracy: 0.6306 89/124 [====================>.........] - ETA: 4s - loss: 0.7558 - masked_accuracy: 0.6309 90/124 [====================>.........] - ETA: 4s - loss: 0.7555 - masked_accuracy: 0.6311 91/124 [=====================>........] - ETA: 4s - loss: 0.7548 - masked_accuracy: 0.6314 92/124 [=====================>........] - ETA: 3s - loss: 0.7545 - masked_accuracy: 0.6315 93/124 [=====================>........] - ETA: 3s - loss: 0.7541 - masked_accuracy: 0.6315 94/124 [=====================>........] - ETA: 3s - loss: 0.7539 - masked_accuracy: 0.6315 95/124 [=====================>........] - ETA: 3s - loss: 0.7540 - masked_accuracy: 0.6315 96/124 [======================>.......] - ETA: 3s - loss: 0.7534 - masked_accuracy: 0.6315 97/124 [======================>.......] - ETA: 3s - loss: 0.7531 - masked_accuracy: 0.6315 98/124 [======================>.......] - ETA: 3s - loss: 0.7531 - masked_accuracy: 0.6314 99/124 [======================>.......] - ETA: 3s - loss: 0.7527 - masked_accuracy: 0.6316100/124 [=======================>......] - ETA: 2s - loss: 0.7525 - masked_accuracy: 0.6316101/124 [=======================>......] - ETA: 2s - loss: 0.7524 - masked_accuracy: 0.6315102/124 [=======================>......] - ETA: 2s - loss: 0.7526 - masked_accuracy: 0.6313103/124 [=======================>......] - ETA: 2s - loss: 0.7524 - masked_accuracy: 0.6313104/124 [========================>.....] - ETA: 2s - loss: 0.7517 - masked_accuracy: 0.6314105/124 [========================>.....] - ETA: 2s - loss: 0.7514 - masked_accuracy: 0.6315106/124 [========================>.....] - ETA: 2s - loss: 0.7506 - masked_accuracy: 0.6318107/124 [========================>.....] - ETA: 2s - loss: 0.7502 - masked_accuracy: 0.6320108/124 [=========================>....] - ETA: 1s - loss: 0.7501 - masked_accuracy: 0.6321109/124 [=========================>....] - ETA: 1s - loss: 0.7496 - masked_accuracy: 0.6321110/124 [=========================>....] - ETA: 1s - loss: 0.7491 - masked_accuracy: 0.6322111/124 [=========================>....] - ETA: 1s - loss: 0.7489 - masked_accuracy: 0.6323112/124 [==========================>...] - ETA: 1s - loss: 0.7490 - masked_accuracy: 0.6322113/124 [==========================>...] - ETA: 1s - loss: 0.7485 - masked_accuracy: 0.6323114/124 [==========================>...] - ETA: 1s - loss: 0.7483 - masked_accuracy: 0.6323115/124 [==========================>...] - ETA: 1s - loss: 0.7480 - masked_accuracy: 0.6324116/124 [===========================>..] - ETA: 0s - loss: 0.7477 - masked_accuracy: 0.6324117/124 [===========================>..] - ETA: 0s - loss: 0.7473 - masked_accuracy: 0.6326118/124 [===========================>..] - ETA: 0s - loss: 0.7468 - masked_accuracy: 0.6327119/124 [===========================>..] - ETA: 0s - loss: 0.7465 - masked_accuracy: 0.6327120/124 [============================>.] - ETA: 0s - loss: 0.7469 - masked_accuracy: 0.6326121/124 [============================>.] - ETA: 0s - loss: 0.7467 - masked_accuracy: 0.6326122/124 [============================>.] - ETA: 0s - loss: 0.7466 - masked_accuracy: 0.6325123/124 [============================>.] - ETA: 0s - loss: 0.7459 - masked_accuracy: 0.6326