{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f982576e-96e2-4457-92e9-a4a7fa244c18",
   "metadata": {},
   "source": [
    "### Code for generating the geotiffs that hold the training and validation points used for training the Transformer and SpaRTA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81423c9-8808-4451-9a26-9805c1ff89db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from rasterio.transform import from_bounds\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sparta.common import Tile, read_image_bounds, tile_bounds, pool_map\n",
    "from sparta.common import output_meta, write_gtiff, get_proj_rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f050984-4dfe-4612-8230-59fa9f1b530d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_paths = {\n",
    "    \"image\": \"leafon{year}.tif\",\n",
    "    \"target\": \"NLCD_{year}_Land_Cover.tif\",\n",
    "   }\n",
    "train_years = ['2001', '2004', '2006', '2008', '2011', '2013', '2016', '2019']\n",
    "train_sequence = ['2001', '2001', '2001', '2004', '2004', '2006', '2006', '2008', '2008', '2008', '2011', '2011', '2013', '2013', '2013', '2016', '2016', '2016', '2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797ac943-fe9b-4fa2-b08e-3eb76156b426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ard_tiles = [Tile(3, 10), Tile(4, 1), Tile(13, 13), Tile(20, 8), Tile(24, 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d505982-844d-40d1-9786-22b137edc81c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tile_target_points(bounds: rio.coords.BoundingBox) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataframe of x, y geopoints and the corresponding class label given bounds\n",
    "    \"\"\"\n",
    "    train, _ = read_image_bounds(train_paths['target'].replace('{year}', '2016'), bounds)\n",
    "    xx, yy = np.meshgrid(np.arange(bounds.left, bounds.right, 30), np.arange(bounds.top, bounds.bottom, -30), indexing='ij')\n",
    "    return pd.DataFrame({'x': np.round(xx[:5000, :5000].ravel()).astype(int), 'y': np.round(yy[:5000, :5000].ravel()).astype(int),\n",
    "                          'train': train.squeeze().T[:5000, :5000].ravel()})\n",
    "\n",
    "def get_sampled_points(tile_points):\n",
    "    \"\"\"\n",
    "    Samples points from all ard tiles -> strategy_options applied PER TILE hence (class_max * ntiles)\n",
    "    \"\"\"\n",
    "    data = tile_points[tile_points['train'] != 0]\n",
    "    data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    samples = data.sample(frac=min(3000000 / len(data), 1), random_state=42)\n",
    "    other = data[~(data.index.isin(samples.index))]\n",
    "\n",
    "    nsamples = len(samples)\n",
    "    min_samples = int(0.02 * nsamples)\n",
    "    extra_samples = {}\n",
    "    for key, val in samples['train'].value_counts().to_dict().items():\n",
    "        if val < min_samples:\n",
    "            extra_samples[key] = min_samples - val\n",
    "    extra_data = []\n",
    "    if len(extra_samples) > 0:\n",
    "        print(\"need extra\")\n",
    "        print(extra_samples)\n",
    "        for key, val in extra_samples.items():\n",
    "            odata = other[other['train'] == key].sample(frac=1, random_state=42)\n",
    "            sample_rate = min(1, val / len(odata))\n",
    "            extra_data.append(odata.sample(frac=sample_rate, random_state=42))\n",
    "        final_samples = pd.concat([samples, pd.concat(extra_data)]).reset_index(drop=True)\n",
    "\n",
    "        return final_samples[['x', 'y', 'train']]\n",
    "    print(\"no extra\")\n",
    "    return samples[['x', 'y', 'train']]\n",
    "\n",
    "\n",
    "def convert_coord(sample: tuple, affine: tuple) -> np.array:\n",
    "    \"\"\"\n",
    "    Converts geographic points to array indexes\n",
    "    \"\"\"\n",
    "    row, col = rio.transform.rowcol(affine, sample[0], sample[1])\n",
    "    return np.array([row, col])\n",
    "\n",
    "def convert_coords(affine: tuple, coords: list) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts list of coordinates into array indexes\n",
    "    \"\"\"\n",
    "    return np.array(pool_map(partial(convert_coord, affine=affine), coords))\n",
    "\n",
    "def out_array(bounds: rio.coords.BoundingBox, train_inds: np.ndarray, val_inds: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Output array for union of all tile bounds -> writes training points : 1,  validation points: 2\n",
    "    \"\"\"\n",
    "    array = np.zeros((int((bounds.top - bounds.bottom) / 30),\n",
    "                       int((bounds.right - bounds.left) / 30)))\n",
    "    array[(train_inds[:, 0], train_inds[:, 1])] = 1\n",
    "    array[(val_inds[:, 0], val_inds[:, 1])] = 2\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3293d3cd-38dd-4ec4-ab5e-edd0c88d6686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile(h=3, v=10)\n",
      "need extra\n",
      "{46: 5792, 22: 10649, 24: 40526, 11: 42349, 81: 47234, 95: 48489, 41: 50894, 43: 54285, 90: 55248, 12: 57857}\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 2670392/2670392 [02:37<00:00, 16990.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 667599/667599 [00:39<00:00, 16997.54it/s]\n",
      "Tile(h=4, v=1)\n",
      "need extra\n",
      "{46: 5460, 23: 9886, 90: 16452, 95: 23713, 12: 26049, 24: 42377}\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 2499149/2499149 [02:24<00:00, 17320.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 624788/624788 [00:36<00:00, 16889.36it/s]\n",
      "Tile(h=13, v=13)\n",
      "need extra\n",
      "{11: 17026, 42: 24328, 22: 37834, 95: 42136, 81: 49565, 23: 49832, 41: 53986, 24: 56149, 31: 56284, 45: 59091, 90: 59579, 43: 59841, 46: 59866}\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 2664885/2664885 [02:36<00:00, 17030.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 666222/666222 [00:38<00:00, 17287.14it/s]\n",
      "Tile(h=20, v=8)\n",
      "need extra\n",
      "{23: 1395, 11: 9537, 43: 11747, 90: 18972, 24: 40495, 95: 49622, 71: 52732, 31: 57278, 42: 58812, 46: 59188, 45: 59382, 52: 59810}\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 2579944/2579944 [02:30<00:00, 17112.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 644986/644986 [00:37<00:00, 17174.13it/s]\n",
      "Tile(h=24, v=13)\n",
      "need extra\n",
      "{24: 3556, 45: 28791, 71: 47474, 31: 52178, 82: 54795, 95: 56732, 52: 59445}\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 2558147/2558147 [02:29<00:00, 17162.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 639537/639537 [00:37<00:00, 17200.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for tile in ard_tiles:\n",
    "    print(tile)\n",
    "    bounds = tile_bounds(tile.h, tile.v)\n",
    "    all_points = tile_target_points(bounds)\n",
    "    sampled_points = get_sampled_points(all_points)\n",
    "    X = sampled_points[['x', 'y']]\n",
    "    y = sampled_points['train']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    train_geos = list(X_train.to_numpy())\n",
    "    val_geos = list(X_test.to_numpy())\n",
    "    affine = from_bounds(*bounds, 5000, 5000)\n",
    "    train_inds = convert_coords(affine, train_geos)\n",
    "    val_inds = convert_coords(affine, val_geos)\n",
    "    oarray = out_array(bounds, train_inds, val_inds).astype(np.uint8)\n",
    "    write_gtiff(oarray, f'./samples/h{tile.h:02}v{tile.v:02}_sample_points.tif', output_meta(affine, get_proj_rio(train_paths['target'].replace('{year}', '2016'))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
